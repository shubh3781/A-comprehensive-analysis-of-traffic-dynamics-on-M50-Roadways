{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6ab71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+---+----+------+------+-----------+-----------+----+--------+------------+----------------+-----+---------+------+-------+----+-----+------+-----------+--------+------------+-------------+-----------+------------+\n",
      "|cosit|year|month|day|hour|minute|second|millisecond|minuteofday|lane|lanename|straddlelane|straddlelanename|class|classname|length|headway| gap|speed|weight|temperature|duration|validitycode|numberofaxles|axleweights|axlespacings|\n",
      "+-----+----+-----+---+----+------+------+-----------+-----------+----+--------+------------+----------------+-----+---------+------+-------+----+-----+------+-----------+--------+------------+-------------+-----------+------------+\n",
      "|  998|2021|    1| 29|   2|    15|     1|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.1|   1.57|1.44| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     1|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.6|   1.62|1.93| 71.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     2|          0|        135|   2|    Ch 2|           0|            null|    2|      CAR|   5.2|   1.28|1.01| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     2|          0|        135|   1|    Ch 1|           0|            null|    5|  HGV_RIG|  11.1|   1.17|1.53| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     4|          0|        135|   2|    Ch 2|           0|            null|    2|      CAR|   5.2|   1.04|1.03| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     4|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.1|   1.04|0.72| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     5|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.3|    1.0|1.03| 70.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     5|          0|        135|   2|    Ch 2|           0|            null|    2|      CAR|   5.3|   1.32|1.33| 71.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     7|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.3|   1.59|1.93| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     9|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.1|   3.26|3.23| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|     9|          0|        135|   2|    Ch 2|           0|            null|    2|      CAR|   5.2|   1.14|0.81| 71.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    10|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.0|   1.28|1.33| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    11|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.3|    1.3|1.64| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    12|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.1|   1.36|1.34| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    13|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.5|   1.24|1.31| 71.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    14|          0|        135|   1|    Ch 1|           0|            null|    5|  HGV_RIG|  11.3|   1.31|1.73| 70.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    15|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.0|   1.54|1.22| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    15|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.2|   1.59|1.52| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    17|          0|        135|   2|    Ch 2|           0|            null|    5|  HGV_RIG|  11.4|   1.65|1.72| 71.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "|  998|2021|    1| 29|   2|    15|    17|          0|        135|   1|    Ch 1|           0|            null|    2|      CAR|   5.0|   1.54|1.54| 69.0|   0.0|        0.0|       0|           0|            0|       null|        null|\n",
      "+-----+----+-----+---+----+------+------+-----------+-----------+----+--------+------------+----------------+-----+---------+------+-------+----+-----+------+-----------+--------+------------+-------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('PySparkShell').setMaster('local')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "##Read file:\n",
    "\n",
    "tiidf = spark.read.csv('hdfs://127.0.0.1:9000/data/*.csv', inferSchema = True, header = True)\n",
    "tiidf.createOrReplaceTempView('tables')\n",
    "tiidf.show(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cddfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+\n",
      "|classname|  count|percentage|\n",
      "+---------+-------+----------+\n",
      "|      CAR|1824109|      71.2|\n",
      "|      LGV| 404379|      15.8|\n",
      "|  HGV_ART| 182570|       7.1|\n",
      "|  HGV_RIG| 105864|       4.1|\n",
      "|      BUS|  19511|       0.8|\n",
      "|  CARAVAN|  16979|       0.7|\n",
      "|    MBIKE|   7957|       0.3|\n",
      "|     null|      0|       0.0|\n",
      "+---------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1=spark.sql(\"SELECT classname, COUNT(classname) AS count,\\\n",
    "round(count(classname)*100 / (select count(*) from tables),1) \\\n",
    "AS percentage from tables  GROUP BY classname ORDER BY percentage desc\")\n",
    "q1.show()\n",
    "q1.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "options(table=\"q1\", keyspace=\"assignment2\").save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38695e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|hour| count|\n",
      "+----+------+\n",
      "|  16|226293|\n",
      "|  15|218875|\n",
      "|  17|211984|\n",
      "|  14|196156|\n",
      "|   8|195373|\n",
      "|   7|190449|\n",
      "|  13|182303|\n",
      "|  11|151449|\n",
      "|  10|141421|\n",
      "|  18|132065|\n",
      "|  12|131667|\n",
      "|   6|113877|\n",
      "|   9|104512|\n",
      "|  19| 93599|\n",
      "|  20| 72506|\n",
      "|  21| 48493|\n",
      "|   5| 39082|\n",
      "|  22| 27680|\n",
      "|  23| 22399|\n",
      "|   4| 15991|\n",
      "|   0| 15624|\n",
      "|   1| 11214|\n",
      "|   2|  9731|\n",
      "|   3|  8797|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = spark.sql(\"SELECT hour, count(hour) AS count from tables GROUP BY hour ORDER BY count desc \")\n",
    "q2.show(24)\n",
    "q2.write.format(\"org.apache.spark.sql.cassandra\").options(table=\"q2\", keyspace=\"assignment2\").save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d1cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|hour| count|\n",
      "+----+------+\n",
      "|   9|104512|\n",
      "|   8|195373|\n",
      "|  10|141421|\n",
      "|  11|151449|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mor_rush = [8,9,10,11]\n",
    "eve_rush = [17,18,19,20]\n",
    "q3 = spark.sql(\"SELECT hour, count(hour) AS count from tables WHERE hour IN (8,9,10,11)\\\n",
    "GROUP BY hour \")\n",
    "q3.show()\n",
    "q3.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "options(table=\"q3\", keyspace=\"assignment2\").save(mode=\"append\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8358a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|hour| count|\n",
      "+----+------+\n",
      "|  20| 72506|\n",
      "|  19| 93599|\n",
      "|  17|211984|\n",
      "|  18|132065|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3eve = spark.sql(\"SELECT hour, count(hour) AS count from tables WHERE hour IN (17,18,19,20)\\\n",
    "GROUP BY hour\")\n",
    "q3eve.show()\n",
    "q3eve.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "options(table=\"q3eve\", keyspace=\"assignment2\").save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c471e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "| cosit|avgspeed|\n",
      "+------+--------+\n",
      "|200718|  109.76|\n",
      "|  1591|   79.29|\n",
      "|  1025|   92.51|\n",
      "|  1507|   102.4|\n",
      "|  1522|   92.62|\n",
      "|  1721|   74.08|\n",
      "| 31031|  110.23|\n",
      "|  1303|   71.91|\n",
      "|200714|   46.66|\n",
      "|200722|    95.6|\n",
      "|  1223|   78.81|\n",
      "| 20671|   71.89|\n",
      "| 20221|   93.14|\n",
      "|  1016|  115.38|\n",
      "| 20223|   85.68|\n",
      "|  1133|   85.42|\n",
      "| 20021|    93.9|\n",
      "|  1331|   97.29|\n",
      "|  1561|   91.42|\n",
      "|200713|  102.91|\n",
      "+------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            junction|cosit|\n",
      "+--------------------+-----+\n",
      "|Junction3- junction4| 1500|\n",
      "| Junction4-junction5| 1501|\n",
      "| Junction5-junction6| 1502|\n",
      "| Junction6-junction7| 1508|\n",
      "| Junction7-junction9| 1503|\n",
      "|Junction9-junction10| 1509|\n",
      "|Junction10-juncti...| 1504|\n",
      "|Junction11-juncti...| 1505|\n",
      "|Junction12-juncti...| 1506|\n",
      "|Junction13-juncti...| 1507|\n",
      "|Junction14-juncti...|15010|\n",
      "|Junction15-juncti...|15011|\n",
      "|Junction16-juncti...|15012|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4avg = spark.sql(\"SELECT cosit, round(AVG(speed),2) AS avgspeed from tables GROUP BY cosit\")\n",
    "q4avg.show()\n",
    "q4junlst =[(\"Junction3- junction4\", 1500),(\"Junction4-junction5\", 1501),(\"Junction5-junction6\", 1502),(\"Junction6-junction7\",1508),(\"Junction7-junction9\",1503),(\"Junction9-junction10\",1509),(\"Junction10-junction11\",1504),(\"Junction11-junction12\",1505),(\"Junction12-junction13\",1506),(\"Junction13-junction14\",1507),(\"Junction14-junction15\",15010),(\"Junction15-junction16\",15011),(\"Junction16-junction17\",15012)]\n",
    "juncs= sc.parallelize(q4junlst).collect()\n",
    "q4jun=spark.createDataFrame(juncs, [\"junction\",\"cosit\"])\n",
    "q4jun.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e01d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:140: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+\n",
      "|cosit|avgspeed|            junction|\n",
      "+-----+--------+--------------------+\n",
      "|15011|   102.6|Junction15-juncti...|\n",
      "| 1502|    98.0| Junction5-junction6|\n",
      "| 1504|    99.7|Junction10-juncti...|\n",
      "| 1508|    94.9| Junction6-junction7|\n",
      "| 1505|    98.6|Junction11-juncti...|\n",
      "| 1506|   101.6|Junction12-juncti...|\n",
      "|15010|   105.1|Junction14-juncti...|\n",
      "| 1509|    93.1|Junction9-junction10|\n",
      "| 1501|    97.3| Junction4-junction5|\n",
      "|15012|   105.3|Junction16-juncti...|\n",
      "| 1500|    88.9|Junction3- junction4|\n",
      "| 1503|    96.3| Junction7-junction9|\n",
      "| 1507|   102.4|Junction13-juncti...|\n",
      "+-----+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4jun.registerTempTable(\"q4jun\")\n",
    "q4= spark.sql(\"SELECT tables.cosit,round(AVG(tables.speed),1) AS avgspeed,\\\n",
    "q4jun.junction from tables JOIN q4jun ON tables.cosit = q4jun.cosit \\\n",
    "GROUP BY tables.cosit,q4jun.junction \")\n",
    "q4.show()\n",
    "q4.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "options(table=\"q4\", keyspace=\"assignment2\").save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a12907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       location|cosit|\n",
      "+---------------+-----+\n",
      "|TMU M50 001.7 N| 1500|\n",
      "|TMU M50 005.0 N| 1501|\n",
      "|TMU M50 010.0 N| 1502|\n",
      "|TMU M50 015.0 S| 1508|\n",
      "|TMU M50 020.0 N| 1503|\n",
      "|TMU M50 015.0 N| 1509|\n",
      "|TMU M50 025.0 S| 1504|\n",
      "|TMU M50 025.0 N| 1505|\n",
      "|TMU M50 030.0 S| 1506|\n",
      "|TMU M50 035.0 S| 1507|\n",
      "|TMU M50 040.0 S|15010|\n",
      "|TMU M50 035.0 N|15011|\n",
      "|TMU M50 040.0 N|15012|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q5list =[(\"TMU M50 001.7 N\", 1500),(\"TMU M50 005.0 N\", 1501),(\"TMU M50 010.0 N\", 1502),(\"TMU M50 015.0 S\",1508),(\"TMU M50 020.0 N\",1503),(\"TMU M50 015.0 N\",1509),(\"TMU M50 025.0 S\",1504),(\"TMU M50 025.0 N\",1505),(\"TMU M50 030.0 S\",1506),(\"TMU M50 035.0 S\",1507),(\"TMU M50 040.0 S\",15010),(\"TMU M50 035.0 N\",15011),(\"TMU M50 040.0 N\",15012)]\n",
    "q5mp= sc.parallelize(q5list).collect()\n",
    "q5loclist=spark.createDataFrame(q5mp, [\"location\",\"cosit\"])\n",
    "q5loclist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa906c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------------+\n",
      "|cosit|count|       location|\n",
      "+-----+-----+---------------+\n",
      "| 1508| 6840|TMU M50 015.0 S|\n",
      "| 1502| 6778|TMU M50 010.0 N|\n",
      "| 1503| 6556|TMU M50 020.0 N|\n",
      "| 1501| 6160|TMU M50 005.0 N|\n",
      "| 1500| 4596|TMU M50 001.7 N|\n",
      "| 1509| 2788|TMU M50 015.0 N|\n",
      "| 1504| 2146|TMU M50 025.0 S|\n",
      "| 1506| 1922|TMU M50 030.0 S|\n",
      "| 1505| 1856|TMU M50 025.0 N|\n",
      "| 1507| 1433|TMU M50 035.0 S|\n",
      "+-----+-----+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q5loclist.registerTempTable(\"q5loclist\")\n",
    "q5 = spark.sql(\"SELECT  Distinct tables.cosit,  count(tables.cosit) AS count,\\\n",
    "q5loclist.location from tables JOIN q5loclist ON tables.cosit = q5loclist.cosit \\\n",
    "WHERE tables.classname ='HGV_RIG' OR tables.classname = 'HGV_ART'  \\\n",
    "GROUP BY tables.cosit, q5loclist.location ORDER BY count desc\");\n",
    "q5.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e73fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "options(table=\"q5\", keyspace=\"assignment2\").save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5331bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
